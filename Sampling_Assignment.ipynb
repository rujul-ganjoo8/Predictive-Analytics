{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuE2aT24UV1a",
        "outputId": "59823ae3-32b9-4dfd-a520-52e4ac9b2b34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1121458924.py:43: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return df.groupby(target, group_keys=False).apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy Table (%):\n",
            "\n",
            "              M1_LogisticRegression  M2_KNN  M3_SVM  M4_DecisionTree  \\\n",
            "SimpleRandom                  94.08   97.51   97.82            99.38   \n",
            "Systematic                    88.65   96.51   96.94            98.25   \n",
            "Stratified                    90.97   95.64   97.51            97.82   \n",
            "Cluster                      100.00  100.00  100.00           100.00   \n",
            "Bootstrap                     95.41   98.69   98.69            99.56   \n",
            "\n",
            "              M5_RandomForest  \n",
            "SimpleRandom            100.0  \n",
            "Systematic              100.0  \n",
            "Stratified              100.0  \n",
            "Cluster                 100.0  \n",
            "Bootstrap               100.0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/Creditcard_data.csv\")\n",
        "\n",
        "X = df.drop(\"Class\", axis=1)\n",
        "y = df[\"Class\"]\n",
        "\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_bal, y_bal = ros.fit_resample(X, y)\n",
        "\n",
        "balanced_df = pd.concat([X_bal, y_bal], axis=1)\n",
        "\n",
        "\n",
        "def simple_random_sampling(df, frac=0.7):\n",
        "    return df.sample(frac=frac, random_state=42)\n",
        "\n",
        "def systematic_sampling(df, step=2):\n",
        "    return df.iloc[::step]\n",
        "\n",
        "def stratified_sampling(df, target=\"Class\", frac=0.7):\n",
        "    return df.groupby(target, group_keys=False).apply(\n",
        "        lambda x: x.sample(frac=frac, random_state=42)\n",
        "    )\n",
        "\n",
        "def cluster_sampling(df, cluster_col=\"Time\"):\n",
        "    df[\"cluster\"] = pd.qcut(df[cluster_col], q=5, labels=False)\n",
        "    chosen_cluster = np.random.choice(df[\"cluster\"].unique())\n",
        "    return df[df[\"cluster\"] == chosen_cluster].drop(\"cluster\", axis=1)\n",
        "\n",
        "def bootstrap_sampling(df):\n",
        "    return df.sample(frac=1, replace=True, random_state=42)\n",
        "\n",
        "sampling_methods = {\n",
        "    \"SimpleRandom\": simple_random_sampling(balanced_df),\n",
        "    \"Systematic\": systematic_sampling(balanced_df),\n",
        "    \"Stratified\": stratified_sampling(balanced_df),\n",
        "    \"Cluster\": cluster_sampling(balanced_df),\n",
        "    \"Bootstrap\": bootstrap_sampling(balanced_df)\n",
        "}\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"M1_LogisticRegression\": LogisticRegression(max_iter=1000),\n",
        "    \"M2_KNN\": KNeighborsClassifier(),\n",
        "    \"M3_SVM\": SVC(),\n",
        "    \"M4_DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"M5_RandomForest\": RandomForestClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "\n",
        "results = {}\n",
        "\n",
        "for samp_name, samp_df in sampling_methods.items():\n",
        "    X_s = samp_df.drop(\"Class\", axis=1)\n",
        "    y_s = samp_df[\"Class\"]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_s, y_s, test_size=0.3, stratify=y_s, random_state=42\n",
        "    )\n",
        "\n",
        "    results[samp_name] = {}\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        pipe = Pipeline([\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"model\", model)\n",
        "        ])\n",
        "\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_pred = pipe.predict(X_test)\n",
        "\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        results[samp_name][model_name] = round(acc * 100, 2)\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nAccuracy Table (%):\\n\")\n",
        "print(results_df)\n"
      ]
    }
  ]
}